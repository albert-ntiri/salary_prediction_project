{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions Based on Job Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import your libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#your info here\n",
    "__author__ = \"Albert Ntiri\"\n",
    "__email__ = \"albert.ntiri@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('data/train_features.csv')\n",
    "train_salaries = pd.read_csv('data/train_salaries.csv')\n",
    "test_features = pd.read_csv('data/test_features.csv')\n",
    "\n",
    "training_combined = pd.merge(train_features, train_salaries, how='inner', on='jobId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class process_data():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    # Drop rows for 0-salary jobs\n",
    "    def clean_data(self):\n",
    "        self.data.drop(index = self.data[self.data.salary == 0].index, axis = 0, inplace = True)\n",
    "    \n",
    "    # Convert categorical variables to numeric based on hierarchy\n",
    "    def label_encode(self, col, new_col, map_dict):\n",
    "        self.data[new_col] = self.data[col].map(map_dict)\n",
    "    \n",
    "    # Convert non-hierarchical categorical variables to dummy variables\n",
    "    def one_hot_encode(self, col, drop_first=False):\n",
    "        self.data = pd.get_dummies(self.data, columns=[col], drop_first=drop_first)\n",
    "        \n",
    "    # drop single or list of columns\n",
    "    def drop_columns(self, col):\n",
    "        self.data.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    # Use function to convert old values in column to new values in new column\n",
    "    def transform(self, col, new_col, function):\n",
    "        self.data[new_col] = self.data[col].apply(function)\n",
    "    \n",
    "    # Create indicator value\n",
    "    def convert_to_bool(self, string):\n",
    "        if string == 'NONE':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    # Scale numeric variables to 0-1 range\n",
    "    def normalize(self, col, new_col):\n",
    "        self.data[new_col] = preprocessing.Normalizer(norm='max').transform([self.data[col]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def build_model(self, data, model_name, model_type, features, test_size=.2):\n",
    "        features_train, features_test, salary_train, salary_test = train_test_split(data[features], data['salary'], test_size=test_size)\n",
    "\n",
    "        model = model_type.fit(features_train, salary_train)\n",
    "        training_r2 = model.score(features_train, salary_train)\n",
    "\n",
    "        predicted_salary = model.predict(features_test)\n",
    "        test_r2 = r2_score(y_true=salary_test, y_pred=predicted_salary)\n",
    "        mse = mean_squared_error(y_true=salary_test, y_pred=predicted_salary)\n",
    "\n",
    "        model_comparison.loc[model_name] = [training_r2, test_r2, mse]\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict(self, data, model):\n",
    "        predictions = model.predict(data)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will cycle through creating features, tuning models, and training/validing models (steps 7-9) until you've reached your efficacy goal\n",
    "\n",
    "#### Your metric will be MSE and your goal is:\n",
    " - <360 for entry-level data science roles\n",
    " - <320 for senior data science roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 7 Engineer features  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that data is ready for modeling\n",
    "#create any new features needed to potentially enhance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = process_data(training_combined)\n",
    "\n",
    "training_data.clean_data()\n",
    "\n",
    "job_levels = {\n",
    "    'JANITOR': 1,\n",
    "    'JUNIOR': 2,\n",
    "    'SENIOR': 3,\n",
    "    'MANAGER': 4,\n",
    "    'VICE_PRESIDENT': 5,\n",
    "    'CFO': 6,\n",
    "    'CTO': 6,\n",
    "    'CEO': 7\n",
    "}\n",
    "training_data.label_encode('jobType', 'jobLevel', job_levels)\n",
    "\n",
    "degree_levels = {\n",
    "    'NONE': 0,\n",
    "    'HIGH_SCHOOL': 1,\n",
    "    'BACHELORS': 2,\n",
    "    'MASTERS': 3,\n",
    "    'DOCTORAL': 4\n",
    "}\n",
    "training_data.label_encode('degree', 'degreeLevel', degree_levels)\n",
    "\n",
    "training_data.transform('major', 'majorInd', training_data.convert_to_bool)\n",
    "\n",
    "training_data.one_hot_encode('major')\n",
    "\n",
    "training_data.drop_columns('major_NONE')\n",
    "\n",
    "training_data.one_hot_encode('industry', drop_first=True)\n",
    "\n",
    "training_data.normalize('yearsExperience', 'yearsExperience_norm')\n",
    "\n",
    "training_data.normalize('milesFromMetropolis', 'milesFromMetropolis_norm')\n",
    "\n",
    "old_columns = ['jobId', 'companyId', 'jobType', 'degree', 'yearsExperience', 'milesFromMetropolis']\n",
    "training_data.drop_columns(old_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 8 Create models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and tune the models that you brainstormed during part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to include columns that will go into the model\n",
    "model_features = ['jobLevel', 'degreeLevel', 'yearsExperience', 'milesFromMetropolis', 'EDUCATION', 'FINANCE', 'HEALTH', 'OIL', 'SERVICE', 'WEB', 'BIOLOGY', 'BUSINESS', 'CHEMISTRY', 'COMPSCI', 'ENGINEERING', 'LITERATURE', 'MATH', 'PHYSICS']\n",
    "# model_features = ['jobLevel', 'degreeLevel', 'yearsExperience', 'milesFromMetropolis', 'EDUCATION', 'FINANCE', 'HEALTH', 'OIL', 'SERVICE', 'WEB', 'majorInd']\n",
    "model_columns = model_features + ['salary']\n",
    "model_train_full = train_full[model_columns]\n",
    "model_train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "\n",
    "features_train, features_test, salary_train, salary_test = train_test_split(model_train_full[model_features], model_train_full['salary'], test_size=.2)\n",
    "features_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on the training data\n",
    "\n",
    "linearmodel = linear_model.LinearRegression()\n",
    "linearmodel.fit(features_train, salary_train)\n",
    "print(linearmodel.coef_)\n",
    "print(linearmodel.score(features_train, salary_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso & Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso()\n",
    "gridl = GridSearchCV(lasso, {'alpha':[.01,.1,.2,.5,1]})\n",
    "gridl.fit(features_train, salary_train)\n",
    "gridl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=.01).fit(features_train, salary_train)\n",
    "print(lasso.coef_)\n",
    "print(lasso.score(features_train, salary_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.Ridge(normalize=True)\n",
    "gridr = GridSearchCV(ridge, {'alpha':[.01,.1,.2,.5,1]})\n",
    "gridr.fit(features_train, salary_train)\n",
    "gridr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.Ridge(normalize=True, alpha=.01).fit(features_train, salary_train)\n",
    "print(ridge.coef_)\n",
    "print(ridge.score(features_train, salary_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = linear_model.SGDRegressor(penalty='l1', alpha=.01, max_iter=1000).fit(features_train, salary_train)\n",
    "print(SGD.coef_)\n",
    "print(SGD.score(features_train, salary_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingRegressor(n_estimators=500, max_depth=6).fit(features_train, salary_train)\n",
    "print(GB.score(features_train, salary_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 9 Test models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do 5-fold cross validation on models and measure MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear regression model on test data\n",
    "\n",
    "predicted_salary_test = linearmodel.predict(features_test)\n",
    "predicted_salary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R^2 and MSE scores on linear regression model\n",
    "\n",
    "print(mean_squared_error(y_true=salary_test, y_pred=predicted_salary_test))\n",
    "print(r2_score(y_true=salary_test, y_pred=predicted_salary_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into 1 cell and wrap into a function for multiple models\n",
    "\n",
    "def build_model(model_name, model_type, features, test_size=.2):\n",
    "    features_train, features_test, salary_train, salary_test = train_test_split(train_full[features], train_full['salary'], test_size=test_size)\n",
    "    \n",
    "    model = model_type.fit(features_train, salary_train)\n",
    "    training_r2 = model.score(features_train, salary_train)\n",
    "    \n",
    "    predicted_salary = model.predict(features_test)\n",
    "    test_r2 = r2_score(y_true=salary_test, y_pred=predicted_salary)\n",
    "    mse = mean_squared_error(y_true=salary_test, y_pred=predicted_salary)\n",
    "    \n",
    "    model_comparison.loc[model_name] = [training_r2, test_r2, mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model comparison dataframe and initialize different models\n",
    "\n",
    "model_comparison = pd.DataFrame(columns=['Training_R2', 'Test_R2', 'Mean_Squared_Error'])\n",
    "lin_reg = linear_model.LinearRegression(normalize=True)\n",
    "lasso_reg = linear_model.Lasso(alpha=.01)\n",
    "ridge_reg = linear_model.Ridge(normalize=True, alpha=.01)\n",
    "SGD_reg = linear_model.SGDRegressor(penalty='l1', alpha=.01, max_iter=1000)\n",
    "GB_reg = GradientBoostingRegressor(n_estimators=500, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up different features combinations as variables\n",
    "\n",
    "features1_joblevel = ['jobLevel']\n",
    "features2_degree = ['degreeLevel']\n",
    "features3_yearsexperience = ['yearsExperience']\n",
    "features4_milesfrommetropolis = ['milesFromMetropolis']\n",
    "features5_industries = ['EDUCATION', 'FINANCE', 'HEALTH', 'OIL', 'SERVICE', 'WEB']\n",
    "features6_majors = ['BIOLOGY', 'BUSINESS', 'CHEMISTRY', 'COMPSCI', 'ENGINEERING', 'LITERATURE', 'MATH', 'PHYSICS']\n",
    "features7_majorind = ['majorInd']\n",
    "features8_nomajorind = features1_joblevel + features2_degree + features3_yearsexperience + features4_milesfrommetropolis + features5_industries + features6_majors\n",
    "features9_all = features8_nomajorind + features7_majorind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different feature combinations on linear regression model\n",
    "\n",
    "build_model('LIN-REG_joblevel', lin_reg, features=features1_joblevel)\n",
    "build_model('LIN-REG_degreeLevel', lin_reg, features=features2_degree)\n",
    "build_model('LIN-REG_yearsExperience', lin_reg, features=features3_yearsexperience)\n",
    "build_model('LIN-REG_milesFromMetropolis', lin_reg, features=features4_milesfrommetropolis)\n",
    "build_model('LIN-REG_industries', lin_reg, features=features5_industries)\n",
    "build_model('LIN-REG_majors', lin_reg, features=features6_majors)\n",
    "build_model('LIN-REG_majorInd', lin_reg, features=features7_majorind)\n",
    "build_model('LIN-REG_noMajorInd', lin_reg, features=features8_nomajorind)\n",
    "build_model('LIN-REG_all', lin_reg, features=features9_all)\n",
    "\n",
    "model_comparison\n",
    "\n",
    "# Using all features yields the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different algorithms and compare models\n",
    "\n",
    "build_model('LASSO_all', lasso_reg, features=features9_all)\n",
    "build_model('RIDGE_all', ridge_reg, features=features9_all)\n",
    "build_model('SGD_all', SGD_reg, features=features9_all)\n",
    "build_model('GB_all', GB_reg, features=features9_all)\n",
    "\n",
    "model_comparison\n",
    "\n",
    "# Gradient boosting yields the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train, features_test, salary_train, salary_test\n",
    "\n",
    "X = model_train_full[model_features]\n",
    "y = model_train_full['salary']\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    features_train, features_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    salary_train, salary_test = y[train_index], y[test_index]\n",
    "    GB_reg.fit(features_train, salary_train)\n",
    "    training_r2 = GB_reg.score(features_train, salary_train)\n",
    "    print(training_r2)\n",
    "    \n",
    "    predicted_salary = GB_reg.predict(features_test)\n",
    "    test_r2 = r2_score(y_true=salary_test, y_pred=predicted_salary)\n",
    "    mse = mean_squared_error(y_true=salary_test, y_pred=predicted_salary)\n",
    "    print(test_r2)\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_mse = cross_val_score(GB_reg, X, y,  cv=3, scoring='neg_mean_squared_error')\n",
    "avg_mse = sum(neg_mse) / len(neg_mse) * -1.0\n",
    "print(avg_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 10 Select best model  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the model with the lowest error as your \"production\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the comparisons, the model that will be used for production is gradient boosting with 500 iterations and a max depth of 6.  The R^2 is around .76 and the mean squared error is around 356."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 11 Automate pipeline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write script that trains model on entire training set, saves model to disk,\n",
    "#and scores the \"test\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process training data\n",
    "\n",
    "clean_data(training_data)\n",
    "engineer_features(training_data)\n",
    "build_model('production_model', GB_reg, features=features9_all)\n",
    "GB_reg.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make corresponding changes to test data\n",
    "\n",
    "engineer_features(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 12 Deploy solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your prediction to a csv file or optionally save them as a table in a SQL database\n",
    "#additionally, you want to save a visualization and summary of your prediction and feature importances\n",
    "#these visualizations and summaries will be extremely useful to business stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 13 Measure efficacy ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip this step since we don't have the outcomes for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
